Step 4: Machine Learning
============================================
1. Install Scikit-Learn In your terminal (VS Code), run:
	pip install scikit-learn matplotlib
2. Create the Training Script
- Create a new file: src/train_model.py.
----------------------Code------------------------- 
import pandas as pd
import pickle
from sqlalchemy import create_engine
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import os

# 1. Setup Paths
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DB_PATH = os.path.join(BASE_DIR, 'data', 'retail.db')
MODEL_PATH = os.path.join(BASE_DIR, 'data', 'model_kmeans.pkl')
SCALER_PATH = os.path.join(BASE_DIR, 'data', 'scaler.pkl')

def train():
    print("ðŸš€ Starting Model Training...")
    
    # --- A. LOAD DATA (Same logic as Step 3) ---
    engine = create_engine(f'sqlite:///{DB_PATH}')
    df = pd.read_sql("SELECT * FROM transactions", engine)
    
    # Clean & Prepare RFM (Copying logic for reproducibility)
    df = df.dropna(subset=['Customer ID'])
    df['Customer ID'] = df['Customer ID'].astype(str)
    df['TotalSpend'] = df['Quantity'] * df['Price']
    
    snapshot_date = df['InvoiceDate'].max() + pd.Timedelta(days=1)
    customers = df.groupby(['Customer ID']).agg({
        'InvoiceDate': lambda x: (snapshot_date - x.max()).days,
        'Invoice': 'count',
        'TotalSpend': 'sum'
    })
    customers.rename(columns={'InvoiceDate': 'Recency', 'Invoice': 'Frequency', 'TotalSpend': 'Monetary'}, inplace=True)
    
    # --- B. PREPROCESSING ---
    # K-Means is sensitive to scale. $1000 spend vs 10 frequency is a big gap.
    # We must "Normalize" the data so all features weight equally.
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(customers)
    
    # --- C. TRAIN MODEL ---
    # We choose 3 Clusters: (e.g., Loyal, New, At-Risk)
    print("ðŸ§  Training K-Means Model (3 Clusters)...")
    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
    kmeans.fit(scaled_data)
    
    # Add clusters back to our data to see who is who
    customers['Cluster'] = kmeans.labels_
    
    # --- D. INTERPRET CLUSTERS (The "ROI" Part) ---
    # We calculate the average of each cluster to understand what they represent
    cluster_summary = customers.groupby('Cluster').mean()
    print("\nðŸ“Š Cluster Profiles (Interpret this to assign discounts):")
    print(cluster_summary)
    
    # --- E. SAVE THE SYSTEM ---
    # We save both the Scaler and the Model. 
    # We need the Scaler later to "translate" new user data for the model.
    with open(MODEL_PATH, 'wb') as f:
        pickle.dump(kmeans, f)
    with open(SCALER_PATH, 'wb') as f:
        pickle.dump(scaler, f)
        
    print(f"\nâœ… Model saved to {MODEL_PATH}")

if __name__ == "__main__":
    train()

3. Run the Script

- Run: python src/train_model.py